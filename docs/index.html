<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>ADCompVision Documentation</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" media="screen" href="main.css" />
</head>
<body>
    <h1 style="font-size: 40px">ADCompVision Documentation</h1>
    <h3>Author: Jakub Wlodek</h3>
    <h3>Corresponding Author: Kazimierz Gofron</h3>
    <hr/>
    <h3>Installing the plugin</h3>
    <p>The ADCompVision plugin depends on several external libraries. These include:</p>
    <ul>
        <li>Opencv: Can be built from source from <a href="https://github.com/opencv/opencv">github</a>. Otherwise install from package manager.</li>
        <li>EPICS, Area Detector, and their submodules, all of whuch can be found on github.</li>
    </ul>
    <p>Further installation instructions are located in the README.md file in the top level of <a href = "https://github.com/epicsNSLS2-areaDetector/ADCompVision">this</a>
         repository.</p>
    <hr/>
    <h3>Using ADCompVision</h3>
    <p>This plugin allows for a multitude of Open Computer Vision functions. As a result, each function will use the input/output PVs differently.</p>
    <p>To view how each function uses the inputs and outputs view the manual <a href="manual.html">here.</a><br/>In addition, selecting an option from
    the dropdown menu will populate the input and output descriptions for any that are used by the selected CV function.</p>

    <p>The main CSS screen for the ADCompVision plugin looks as follows:</p>
    <img style="width: 40%;" src = "ADCompVision/MainCVScreen.png" alt = "main">
    <p class="text-section-local">To use the plugin, you must select one of the functions from the three function sets. The other 2 function sets must be set to 'None'
        Then, make sure that the image1 or pv1 plugin has its input port set to be the output port of ADCompVision (CV1). You should pass CV1 to whichever
        plugin you use to display your images. Then, open the main screen, and
        note that input and output descriptions are listed for each function. Enter valid input values for each of the required inputs.
        Next, start image acquisition and enable the plugin. You should see the processed image in image1 ArrayData. Some examples are shown below.
    </p>
    <p class="text-section-local">When using non-8bit cameras, note that many of the CompVision functions supported here require the input image to be downconverted
        to 8 bit in order to work. To do this, select your camera's actual bit depth in the bit depth selector. (NOT NDDataType). If your device is a 12 bit camera for
        example, select 12 bit in the menu, not 16 bit, even if the input has an NDDataType of NDUInt16.
    </p>
    <hr/>

    <h4>Release Notes</h4>

    <!--RELEASE START-->

<h4>R1-2 (???-July-2019)</h4>
<ul>
<li>
<p>Computer Vision functions implemented</p>
<ul>
<li>Video Record - allows for video recording with areaDetector</li>
<li>Convert Format - Converts color format and Data type of input image.</li>
</ul>
</li>
<li>
<p>Additional Feature changes</p>
<ul>
<li>Added filepath PV</li>
<li>Added filepath exists PV</li>
<li>Added opencv_video and opencv_videoio as library dependancies</li>
<li>Added support for multithreading for certain functions</li>
<li>New medm, edm, and adl screens (Courtesy of Mark Rivers)</li>
<li>New rst documentation pages (Courtesy of Mark Rivers</li>
</ul>
</li>
<li>
<p>Bug Fixes</p>
<ul>
<li>Edited mat2NDArray function to remove potential memory leak</li>
<li>Comment + documentation updates</li>
<li>Fixed bug where input pArray data would be placed into the Mat - which would result in data overwrite.</li>
<li>removed call that added unnecessary DataType attribute</li>
<li>Changed <code>doCallbacksGenericPointer</code> to <code>endProcessCallbacks</code></li>
<li>Cleanup of `mat2NDArray` function</li>
</ul>
</li>
</ul>
<h4>R1-1 (17-April-2019)</h4>
<ul>
<li>
<p>Computer Vision functions implemented:</p>
<ul>
<li>Sharpening filter</li>
<li>Image subtraction</li>
<li>Image statistics</li>
<li>Distance between objects</li>
</ul>
</li>
<li>
<p>Additional Feature changes</p>
<ul>
<li>File saving temporarily removed due to crashing issues over ssh and additional dependency</li>
<li>Camera bit depth selector added to play better with higher bit images</li>
<li>Image scaling corrected to account for other bit depth images</li>
<li>Minor screen updates to reflect feature changes</li>
</ul>
</li>
<li>
<p>Bugs Fixed</p>
<ul>
<li>Bug where invalid bit depth could cause IOC to crash</li>
<li>Bug where certain PV would cause error at IOC startup</li>
<li>Fixed Image passthrough to work with any bit depth</li>
<li>Fixed colorspace of color images passed through</li>
<li>Removed code that caused certain compiler warnings - Cleaner compile</li>
</ul>
</li>
</ul>
<h4>R1-0 (14-January-2019)</h4>
<ul>
<li>
<p>Computer Vision functions implemented:</p>
<ul>
<li>Gaussian Blur</li>
<li>Thresholding</li>
<li>Laplacian Edge Detection</li>
<li>Canny Edge Detection</li>
<li>Centroid Detection</li>
<li>User Definable Function</li>
</ul>
</li>
<li>
<p>Additional Features added</p>
<ul>
<li>Processed image file saving. (This can work in tandem with NDPluginFile)</li>
<li>Support for mono or RGB images</li>
<li>Support for 8, 16, 32, and 64 bit images</li>
<li>Flexible and modular function implementation system</li>
<li>CSS User Interface screen</li>
<li>Documentation</li>
</ul>
</li>
<li>
<p>Known Limitations:</p>
<ul>
<li>No current support for performing operations accross multiple images. Required for several CV functions</li>
<li>Conversion between PV and ADCV_Function is convoluted and should be reworked</li>
</ul>
</li>
<li>
<p>Future Release Plans</p>
<ul>
<li>Expand list of supported functions<ul>
<li>Motion Vectors</li>
<li>Object identification</li>
<li>Image alignment</li>
<li>More...</li>
</ul>
</li>
<li>Perform tests with variety of cameras</li>
<li>Performance improvements and bug fixes</li>
<li>Expand file saving to allow for capture, stream, etc</li>
</ul>
</li>
</ul>
    <!--RELEASE END-->

    <hr/>

    <h4>Usage Examples:</h4>

    <p><strong>Thresholding</strong></p>
    <img style="width: 70%;"src = "ADCompVision/threshold.png" alt = "Thresholding">
    <!--<img style="width: 30%;"src = "ADCompVision/threshold_menu.png" alt = "Thresholding Menu">-->
    <p class = "text-section-local">As of R1-0 ADCompVision supports Thresholding. Start by selecting it from the Vision Function 1 dropdown menu.
        Set the threshold value and max pixel value. The max pixel value will almost always be 255 on 8 bit images.
    </p>

    <p><strong>Laplacian Edge Detection</strong></p>
    <img style="width: 70%;"src = "ADCompVision/Laplacian.png" alt = "Laplacian">
    <!--<img style="width: 30%;"src = "ADCompVision/laplacian_menu.png" alt = "Laplacian Menu">-->
    <p class = "text-section-local">As of R1-0 ADCompVision supports Laplacian based edge detection. Start by selecting it from the Vision Function 1 dropdown menu.
        Set the blur degree, kernel size, scale, and delta. Note that the blur degree and kernel size must be odd integers from 1 to 15 (3 usually works best).
        Tweak these parameters until an acceptable result is visible.
    </p>

    <p><strong>Canny edge detection</strong></p>
    <img style="width: 70%;"src = "ADCompVision/Canny2.png" alt = "Canny">
    <!--<img style="width: 30%;"src = "ADCompVision/canny_menu.png" alt = "Canny Menu">-->
    <p class = "text-section-local">As of R1-0 ADCompVision supports Canny based edge detection. Start by selecting it from the Vision Function 1 dropdown menu.
        Set the Threshold value, ratio, blur degree, and kernel size, note that the blur degree and kernel size must be odd integers from 1 to 15 (3 usually works best).
        Tweak these parameters until an acceptable result is visible.
    </p>

    <p><strong>Centroid identification</strong></p>
    <img style="width: 70%;"src = "ADCompVision/Centroid.png" alt = "Centroid">
    <!--<img style="width: 30%;"src = "ADCompVision/centroid_menu.png" alt = "Centroid Menu">-->
    <p class="text-section-local">As of R1-0 ADCompVision supports centroid identification. To use this feature select it from the Function
        set 2 dropdown. Then, set the number of desired objects to find, the blur degree (3 or 5 is usually best), a threshold value, and an upper
        and lower pixel area threshold for the objects. Play around with these numbers until the desired objects are detected. The centroid centers
        are then outputted into the 'Output' PV values
    </p>

    <p><strong>Video Record</strong></p>
    <img style="width: 50%;"src = "ADCompVision/Video_Record.png" alt = "Video Record">
    <p class="text-section-local">As of R1-2, ADCompVision supports writing video recordings for areaDetector. Controls allow for setting
        an output framerate, color and mono video, 4 different encoding formats, and 2 file formats. To start a recording,
        input a valid file path, then enter valid options for framerate and other video modes. Finally simply enter a '1' into
        the 'Start/Stop' field to start recording, and a '0' to stop recording. The video will be saved to the given file path
        and will be called CV_Output_Vid_$TIMESTAMP.avi or .mp4 depending on selection. Note that not all 4 encodings will be supported
        on each machine.
    </p>

    <p><strong>Distance Check</strong></p>
    <img style="width: 70%;"src = "ADCompVision/DistanceCheck.png" alt = "Dist Check">
    <p class="text-section-local">As of R1-2, ADCompVision supports Distance Checking between two objects in an image. To use this feature,
        select it from Function set 3. Then enter a distance threshold in pixels, then a blur size (3 or 5 are usually best), a threshold value,
        select apply blur =  yes (will give better results), and choose an object size threshold in pixels to avoid background noise. Tweak the threshold
        and size values until the two desired objects are detected, and then note that the output pvs print the pixel distance between them, and whether or
        not it is under the distance threshold input variable.
    </p>

    <hr/>

    <h4>Issues and Pull Requests</h4>

    <p>If you wish to create an issue or pull request, please do so at the source fork on
        <a href = "https://github.com/jwlodek/ADCompVision">github.</a>
    </p>
    <hr/>
    <h4>Important Links</h4>

    <a href = "https://github.com/areaDetector">Area Detector on Github</a><br/>
    <a href = "https://github.com/epicsNSLS2-areaDetector">NSLS2 area detector reposiotries on Github</a><br/>
    <a href = "https://github.com/epicsNSLS2-areaDetector/ADCompVision">ADCompVision on Github</a><br/>
    <hr/>
    <h3>copyright: Brookhaven National Laboratory 2018-2019</h3>
</body>
</html>
